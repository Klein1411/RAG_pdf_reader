{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6648ae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x√≥a th∆∞ m·ª•c chromadb c≈©...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "import io\n",
    "\n",
    "# --- 1. Xo√° th∆∞ m·ª•c chromadb c≈© n·∫øu t·ªìn t·∫°i ---\n",
    "if os.path.isdir(\"chromadb\"):\n",
    "    print(\"ƒêang x√≥a th∆∞ m·ª•c chromadb c≈©...\")\n",
    "    shutil.rmtree(\"chromadb\")\n",
    "\n",
    "# --- 3. Ki·ªÉm tra v√† c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt ---\n",
    "def ensure_package(pkg_name, import_name=None):\n",
    "    try:\n",
    "        __import__(import_name or pkg_name)\n",
    "    except ImportError:\n",
    "        print(f\"Thi·∫øu th∆∞ vi·ªán '{pkg_name}', ƒëang c√†i ƒë·∫∑t...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg_name])\n",
    "        __import__(import_name or pkg_name)\n",
    "\n",
    "pkgs = [\n",
    "    (\"chromadb\", None),\n",
    "    (\"langchain\", None),\n",
    "    (\"ollama\", None),\n",
    "    (\"tiktoken\", None),\n",
    "    (\"PyPDF2\", None)\n",
    "]\n",
    "\n",
    "for pkg, imp in pkgs:\n",
    "    ensure_package(pkg, imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a0e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ƒê·ªçc PDF v·ªõi decoder UTF-8 ƒë·ªÉ tr√°nh l·ªói tuple ---\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.schema import Document\n",
    "\n",
    "pdf_path = r\"D:\\Project_self\\pdf_place\\CleanCode.pdf\"  # Thay ƒë∆∞·ªùng d·∫´n t·ªõi file PDF c·ªßa b·∫°n\n",
    "reader = PdfReader(pdf_path)\n",
    "docs = []\n",
    "\n",
    "for i, page in enumerate(reader.pages):\n",
    "    raw_text = page.extract_text() or \"\"\n",
    "    # N·∫øu raw_text l√† bytes, decode b·∫±ng utf-8 v√† b·ªè k√Ω t·ª± kh√¥ng h·ª£p l·ªá\n",
    "    if isinstance(raw_text, (bytes, bytearray)):\n",
    "        text = raw_text.decode(\"utf-8\", errors=\"ignore\")\n",
    "    else:\n",
    "        text = raw_text\n",
    "    docs.append(Document(\n",
    "        page_content=text,\n",
    "        metadata={\"source\": f\"{os.path.basename(pdf_path)}_page_{i+1}\"}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01ebbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cedf5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klein\\AppData\\Local\\Temp\\ipykernel_2900\\1977429318.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# S·ª≠ d·ª•ng embedding model local\n",
    "embed_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40bf5c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ VectorDB kh·ªüi t·∫°o th√†nh c√¥ng v·ªõi model embedding hi·ªán t·∫°i.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klein\\AppData\\Local\\Temp\\ipykernel_2900\\4150500916.py:8: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# --- 7. T·∫°o ho·∫∑c t·∫£i l·∫°i vector database local v·ªõi fallback khi embed th·∫•t b·∫°i ---\n",
    "try:\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embed_model,\n",
    "        persist_directory=\"chromadb\"\n",
    "    )\n",
    "    vectordb.persist()\n",
    "    print(\"üéâ VectorDB kh·ªüi t·∫°o th√†nh c√¥ng v·ªõi model embedding hi·ªán t·∫°i.\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"[Warning] Embed th·∫•t b·∫°i: {e}\")\n",
    "    print(\"Chuy·ªÉn sang model embedding thay th·∫ø: sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    # C√†i v√† d√πng MiniLM embedding local thay th·∫ø\n",
    "    from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "    fallback_embed = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=fallback_embed,\n",
    "        persist_directory=\"chromadb\"\n",
    "    )\n",
    "    vectordb.persist()\n",
    "    embed_model = fallback_embed  # c·∫≠p nh·∫≠t cho ph·∫ßn truy v·∫•n sau\n",
    "    print(\"üéâ VectorDB ƒë√£ kh·ªüi t·∫°o l·∫°i v·ªõi MiniLM embedding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda0dff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key   : ‚úì\n",
      "Model     : meta-llama/llama-3.1-405b-instruct\n",
      "MaxTokens : 512\n",
      "Temperature: 0.7\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, requests\n",
    "\n",
    "# ‚úÖ ƒë·ªçc .env ngay trong th∆∞ m·ª•c project (m·∫∑c ƒë·ªãnh)\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY    = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "MODEL_ID   = os.getenv(\"OPENROUTER_MODEL\", \"anthropic/claude-3.5-sonnet\")\n",
    "PROMPT     = os.getenv(\n",
    "    \"OPENROUTER_PROMPT\",\n",
    "    \"B·∫°n l√† m·ªôt tr·ª£ l√Ω h·ªØu √≠ch. H√£y tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß v√† chi ti·∫øt. ƒê·ª´ng l·∫∑p l·∫°i c√¢u tr·∫£ l·ªùi n·∫øu kh√¥ng c·∫ßn thi·∫øt.\"\n",
    ")\n",
    "MAX_TOKENS = int(os.getenv(\"OPENROUTER_MAX_TOKENS\", \"512\"))\n",
    "TEMP       = float(os.getenv(\"OPENROUTER_TEMPERATURE\", \"0.7\"))\n",
    "\n",
    "# Ki·ªÉm tra\n",
    "print(\"API Key   :\", \"‚úì\" if API_KEY else \"‚úó\")\n",
    "print(\"Model     :\", MODEL_ID)\n",
    "print(\"MaxTokens :\", MAX_TOKENS)\n",
    "print(\"Temperature:\", TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e381f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openrouter(prompt: str) -> str:\n",
    "    global last_call_time\n",
    "\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"‚ùå Thi·∫øu OPENROUTER_API_KEY trong .env\")\n",
    "\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY.strip()}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"X-Title\": \"MyRAGApp\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"meta-llama/llama-3.1-405b-instruct\",   # üëà thay b·∫±ng model m·∫°nh\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"temperature\": TEMP,\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, json=payload, timeout=60)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"‚ùå HTTP\", resp.status_code)\n",
    "        print(\"Resp error:\", resp.text)\n",
    "        resp.raise_for_status()\n",
    "\n",
    "    data = resp.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd876b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ Prompt: T√≥m t·∫Øt ch∆∞∆°ng 1 c·ªßa t√†i li·ªáu PDF cho t√¥i.\n",
      "\n",
      "üéâ OpenRouter tr·∫£ l·ªùi:\n",
      " T√¥i xin l·ªói, nh∆∞ng t√¥i kh√¥ng th·ªÉ m·ªü ho·∫∑c truy c·∫≠p c√°c t·ªáp PDF ho·∫∑c b·∫•t k·ª≥ t·ªáp n√†o kh√°c. Tuy nhi√™n, n·∫øu b·∫°n cung c·∫•p n·ªôi dung c·ªßa ch∆∞∆°ng 1 t√†i li·ªáu PDF ƒë√≥ cho t√¥i, t√¥i s·∫Ω s·∫µn l√≤ng gi√∫p b·∫°n t√≥m t·∫Øt n√≥ m·ªôt c√°ch ƒë·∫ßy ƒë·ªß v√† chi ti·∫øt nh·∫•t c√≥ th·ªÉ.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_prompt = \"T√≥m t·∫Øt ch∆∞∆°ng 1 c·ªßa t√†i li·ªáu PDF cho t√¥i.\"\n",
    "    print(\"üëâ Prompt:\", test_prompt)\n",
    "    try:\n",
    "        answer = call_openrouter(test_prompt)\n",
    "        print(\"\\nüéâ OpenRouter tr·∫£ l·ªùi:\\n\", answer)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå L·ªói:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15132458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.outputs import ChatResult, ChatGeneration\n",
    "import requests\n",
    "\n",
    "class OpenRouterLLM(BaseChatModel):\n",
    "    model: str\n",
    "    api_key: str\n",
    "    max_tokens: int = 512\n",
    "    temperature: float = 0.7\n",
    "    url: str = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager=None,\n",
    "        **kwargs\n",
    "    ) -> ChatResult:\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": m.content}\n",
    "                for m in messages\n",
    "                if isinstance(m, HumanMessage)\n",
    "            ],\n",
    "            \"max_tokens\": kwargs.get(\"max_tokens\", self.max_tokens),\n",
    "            \"temperature\": kwargs.get(\"temperature\", self.temperature),\n",
    "        }\n",
    "\n",
    "        resp = requests.post(self.url, headers=headers, json=payload, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[ChatGeneration(message=AIMessage(content=content))]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"openrouter_custom\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621baec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[32m      4\u001b[39m llm = OpenRouterLLM(\n\u001b[32m      5\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mmeta-llama/llama-3.1-405b-instruct\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENROUTER_API_KEY\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      7\u001b[39m     max_tokens=\u001b[32m512\u001b[39m,\n\u001b[32m      8\u001b[39m     temperature=\u001b[32m0.7\u001b[39m,\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "llm = OpenRouterLLM(\n",
    "    model=\"meta-llama/llama-3.1-405b-instruct\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    max_tokens=512,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "\n",
    "# 2) Load ho·∫∑c build l·∫°i vector DB\n",
    "# V√≠ d·ª•: n·∫øu b·∫°n ƒë√£ c√≥ FAISS index s·∫µn:\n",
    "\n",
    "\n",
    "# 3) T·∫°o retriever\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 3) ƒê·ªãnh nghƒ©a h√†m ask ƒë·ªÉ h·ªèi v√† in k·∫øt qu·∫£ + ngu·ªìn\n",
    "def ask(question: str):\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    print(\"=== ANSWER ===\")\n",
    "    print(result[\"result\"])\n",
    "    print(\"\\n=== SOURCES ===\")\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        print(f\"- {doc.metadata.get('source', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d457149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANSWER ===\n",
      "Here's a summary of the table of contents for the book \"Clean Code\" by Robert C. Martin:\n",
      "\n",
      "1. Clean Code\n",
      "   - Importance of clean code\n",
      "   - What is clean code?\n",
      "\n",
      "2. Meaningful Names\n",
      "   - Naming variables, functions, and classes\n",
      "   - Naming conventions and best practices\n",
      "\n",
      "3. Functions\n",
      "   - Writing small and focused functions\n",
      "   - Function arguments and return values\n",
      "   - Structured programming\n",
      "\n",
      "4. Comments\n",
      "   - When to use comments\n",
      "   - Good and bad comments\n",
      "   - Commenting best practices\n",
      "\n",
      "5. Formatting\n",
      "   - Code formatting guidelines\n",
      "   - Vertical and horizontal formatting\n",
      "   - Team coding standards\n",
      "\n",
      "6. Objects and Data Structures\n",
      "   - Difference between objects and data structures\n",
      "   - Data abstraction and encapsulation\n",
      "   - Law of Demeter\n",
      "\n",
      "7. Error Handling\n",
      "   - Exception handling techniques\n",
      "   - Writing clean error handling code\n",
      "   - Null and error handling patterns\n",
      "\n",
      "8. Boundaries\n",
      "   - Integrating third-party code\n",
      "   - Defining boundaries and interfaces\n",
      "   - Boundary crossing and dependencies\n",
      "\n",
      "9. Unit Tests\n",
      "   - Importance of unit testing\n",
      "   - Writing clean and effective unit tests\n",
      "   - Test-driven development (TDD)\n",
      "\n",
      "10. Classes\n",
      "    - Class design principles\n",
      "    - Cohesion and coupling\n",
      "    - SOLID principles\n",
      "\n",
      "11. Systems\n",
      "    - Separation of concerns\n",
      "    - Dependency injection\n",
      "    - Scaling and performance considerations\n",
      "\n",
      "12. Emergence\n",
      "    - Design patterns and principles\n",
      "    - Refactoring techniques\n",
      "    - Continuous improvement\n",
      "\n",
      "13. Concurrency\n",
      "    - Challenges of concurrent programming\n",
      "    - Principles for writing clean concurrent code\n",
      "    - Testing and debugging concurrent code\n",
      "\n",
      "14. Successive Refinement\n",
      "    - Case study: Refactoring a real-world codebase\n",
      "    - Incremental refactoring and improvement\n",
      "    - Achieving clean code through iterative refinement\n",
      "\n",
      "15. JUnit Internals\n",
      "    - Deep dive into the JUnit framework\n",
      "    - Design and architecture of JUnit\n",
      "    - Lessons learned from JUnit's codebase\n",
      "\n",
      "16. Refactoring SerialDate\n",
      "    - Case study: Refactoring a legacy codebase\n",
      "    - Identifying and addressing code smells\n",
      "    - Improving readability, maintainability, and performance\n",
      "\n",
      "17. Smells and Heuristics\n",
      "    - Code smells and their remedies\n",
      "    - Heuristics for writing clean code\n",
      "    - Common pitfalls and anti-patterns to avoid\n",
      "\n",
      "This table of contents covers\n",
      "\n",
      "=== SOURCES ===\n",
      "- CleanCode.pdf_page_2\n",
      "- CleanCode.pdf_page_166\n",
      "- CleanCode.pdf_page_4\n",
      "- CleanCode.pdf_page_32\n"
     ]
    }
   ],
   "source": [
    "ask(\"t·ªïng h·ª£p table of content clean code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests, os\n",
    "\n",
    "# API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# url = \"https://openrouter.ai/api/v1/models\"\n",
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "# }\n",
    "\n",
    "# resp = requests.get(url, headers=headers)\n",
    "# print(\"Status:\", resp.status_code)\n",
    "# print(resp.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
