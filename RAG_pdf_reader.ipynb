{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Cho phép bypass Execution Policy trong phiên này\n",
        "Set-ExecutionPolicy -ExecutionPolicy Bypass -Scope Process -Force\n",
        "\n",
        "# 2. Kích hoạt venv “t”\n",
        "& .\\t\\Scripts\\Activate.ps1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "đây là đoạn code test RAG truy vấn thông tin từ pdf, nếu muốn truy vấn đa dạng hơn cần sửa đầu đọc file, hoặc đọc folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass\n",
        ".\\t\\Scripts\\Activate.ps1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "venv là t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTWyJhP-vaqE",
        "outputId": "07d04123-275a-4054-f217-06ea3b482866"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:11: SyntaxWarning: invalid escape sequence '\\P'\n",
            "<>:11: SyntaxWarning: invalid escape sequence '\\P'\n",
            "C:\\Users\\klein\\AppData\\Local\\Temp\\ipykernel_30504\\2953363788.py:11: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  text = load_pdfplumber_text(\"D:\\Project_self\\pdf_place\\Report_Team1_DPL302m.pdf\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Report in Course DPL302m\n",
            "Integrating Convolution and Attention for Chest X-ray Lung\n",
            "Disease Classification\n",
            "FPT UNIVERSITy\n",
            "HO CHI MINH CITy\n",
            "July 20, 2025\n",
            "Student:\n",
            "Lecturer:\n",
            "Tran Anh Kiet : SE182050\n",
            "MsC LUU GIANG NAM\n",
            "Thai Thanh Nhan : SE196293\n",
            "Tran Pham Tuan Dung : SE183674Abstract\n",
            "Chest X-ray (CXR) imaging is the most widely used modality for early lung disease\n",
            "detection, covering conditions such as pneumonia, viral infections, and lung\n",
            "opacity. However, accurate diagnosis remains challengi\n"
          ]
        }
      ],
      "source": [
        "import pdfplumber\n",
        "from llama_index.core import Document\n",
        "\n",
        "def load_pdfplumber_text(filepath):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(filepath) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "text = load_pdfplumber_text(\"D:\\Project_self\\pdf_place\\Report_Team1_DPL302m.pdf\")\n",
        "print(text[:500])  # kiểm tra có nội dung chưa\n",
        "\n",
        "documents = [Document(text=text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaKOUuOHwn0j",
        "outputId": "b751dcdd-c8f2-47f4-b4eb-efe48183bb18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'llama_index.core.schema.Document'>\n",
            "33361\n"
          ]
        }
      ],
      "source": [
        "print(type(documents[0]))\n",
        "print(len(documents[0].text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lyeq8_Dwx97",
        "outputId": "913cf48c-aab0-49c7-f052-fadb47f0a6da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 11 nodes.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "\n",
        "parser = SimpleNodeParser()\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "print(f\"Loaded {len(nodes)} nodes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgxswfeFuyEj",
        "outputId": "3a2ac291-5bab-4458-e039-824e98277886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TextNode(id_='a4d551e4-dd54-4ad3-9907-cb0c23e5e3ab', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='dbad727a-88e3-4511-95c6-c0412697378a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccfd030b4a272e94cb9f39497971acd28e429be54ff8a8423eeaf22ed7f6ee9d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Final Report in Course DPL302m\\nIntegrating Convolution and Attention for Chest X-ray Lung\\nDisease Classification\\nFPT UNIVERSITy\\nHO CHI MINH CITy\\nJuly 20, 2025\\nStudent:\\nLecturer:\\nTran Anh Kiet : SE182050\\nMsC LUU GIANG NAM\\nThai Thanh Nhan : SE196293\\nTran Pham Tuan Dung : SE183674Abstract\\nChest X-ray (CXR) imaging is the most widely used modality for early lung disease\\ndetection, covering conditions such as pneumonia, viral infections, and lung\\nopacity. However, accurate diagnosis remains challenging due to subtle\\nradiographic features, overlapping anatomical structures, and the shortage of\\nexperienced radiologists. This paper proposes a lightweight CNN, InceptionV3, and\\nVision Transformer (ViT) to classify lung diseases from CXR images. The model\\nleverages transfer learning to address data scarcity and incorporates robust\\npreprocessing, including contrast enhancement and extensive data augmentation,\\nto improve generalization. Grad-CAM visualizations are employed to enhance\\nmodel interpretability, allowing verification of the diagnostic regions.\\nExperimental results on the Kaggle Lung Disease dataset outperforming baseline\\nmodels such as CNN (82.59% accuracy, 82% F1-score, 0.95 AUC), InceptionV3\\n(94.53% accuracy, 95% F1-score, 0.99 AUC), and Vision Transformer (93.96%\\naccuracy, 94% F1-score, 0.99 AUC). The confusion matrix confirms balanced\\nperformance across classes, with 95% correct classification for Viral Pneumonia,\\n86% for Normal, and 80% for Lung Opacity. The proposed framework offers a\\npractical solution for clinical deployment, balancing diagnostic accuracy,\\ncomputational efficiency, and medical transparency.\\nKeywords: Lung disease detection, Inception-v3, Convolutional Neural Networks (CNN),\\nVision Transformer, Chest X-ray classification.\\n2Contents\\nContents\\n1 Introduction 4\\n2 Related Works 5\\n3 Contribution 6\\n4 Data and Models 7\\nMethodology\\n1. Data Preparation\\n2. Model Architecture\\n2.1. Convolutional Neural Network (CNN)\\n2.2. InceptionV3\\n2.3. Vision Transformer (ViT)\\n3. Training Objectives and Loss Functions\\n5 Experiment 13\\n5.1. Implementation Detail\\n5.2. Result Analysis\\n5.3. Qualitative Result\\nInceptionV3 Performance Analysis\\nCNN Performance Analysis\\nVision Transformer (ViT) Performance Analysis\\nComparative Performance Visualization\\n5.4. Comparative Evaluation with Existing Methods\\nQuantitative and Qualitative Comparison\\nFinal Remarks\\n6 Conclusion and Perspectives 23\\nReferences 24\\nName Student ID Tasks\\nTran Anh Kiet SE182050 Write report, edit report, edit slides, present 1, 2, 3, 4.\\nTran Pham Tuan Dung SE183674 Run model cnn, edit slides, present 4.\\nThai Thanh Nhan SE196293 Run model InceptionV3, ViT, run demo, present 5, 6.\\nFinal Report in Course DPL302m 31 Introduction\\n1 Introduction\\nLung diseases such as pneumonia, viral infections, and lung opacity remain leading\\ncauses of morbidity and mortality worldwide. Chest X-ray imaging is the primary\\ndiagnostic tool in clinical practice due to its accessibility, low cost, and fast\\nacquisition.\\nDespite its widespread use, interpreting CXR images presents significant challenges.\\nRadiographic features of lung diseases are often subtle and can overlap with normal\\nanatomical structures such as ribs and the heart shadow, making accurate diagnosis\\ndifficult. The shortage of trained radiologists, especially in low-resource settings,\\nexacerbates the risk of misdiagnosis and delayed treatment. Artificial intelligence,\\nparticularly deep learning, has emerged as a promising approach to automate\\nmedical image analysis and assist clinicians in disease detection. However, applying\\ndeep learning to CXR classification faces multiple obstacles.\\nThese include limited dataset availability, class imbalance, subtle variations\\nbetween disease categories, and the necessity for model explainability to foster\\nclinical trust. Furthermore, real-world applications require models that are\\ncomputationally efficient and robust across diverse imaging conditions. To address\\nthese challenges, we propose a model Convolutional Neural Networks (CNN),\\nInceptionV3, and Vision Transformer (ViT).\\nData augmentation is implemented to prevent overfitting and improve robustness\\nto imaging variations. Grad-CAM-based explainability tools are incorporated,\\nproviding visual explanations of the model's decision-making process and enabling\\nclinical verification.\", mimetype='text/plain', start_char_idx=0, end_char_idx=4343, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='dbad727a-88e3-4511-95c6-c0412697378a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='a4d551e4-dd54-4ad3-9907-cb0c23e5e3ab', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a40c3aea9d6f204f1729524e54374849447eadc2002c09a293fc175e06de4d24'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5b2a3c41-2c59-4839-979c-e6ef79ccd13f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f99ac509b749e9e9ab9b37c0a790da14675421f1ea8cbbcae907ee5091f153f4')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"The shortage of trained radiologists, especially in low-resource settings,\\nexacerbates the risk of misdiagnosis and delayed treatment. Artificial intelligence,\\nparticularly deep learning, has emerged as a promising approach to automate\\nmedical image analysis and assist clinicians in disease detection. However, applying\\ndeep learning to CXR classification faces multiple obstacles.\\nThese include limited dataset availability, class imbalance, subtle variations\\nbetween disease categories, and the necessity for model explainability to foster\\nclinical trust. Furthermore, real-world applications require models that are\\ncomputationally efficient and robust across diverse imaging conditions. To address\\nthese challenges, we propose a model Convolutional Neural Networks (CNN),\\nInceptionV3, and Vision Transformer (ViT).\\nData augmentation is implemented to prevent overfitting and improve robustness\\nto imaging variations. Grad-CAM-based explainability tools are incorporated,\\nproviding visual explanations of the model's decision-making process and enabling\\nclinical verification. This research contributes a comprehensive solution to the\\nproblem of automated lung disease classification from CXR images, focusing on\\naccuracy, interpretability, and computational efficiency to support deployment in\\nreal-world healthcare environments.\\nFinal Report in Course DPL302m 42 Related Works\\n2 Related Works\\nDeep learning has significantly advanced the field of lung disease detection from\\nchest X-ray images. Rajpurkar et al. proposed CheXNet, a DenseNet121-based model\\ntrained on over 100,000 CXR images from the NIH dataset, achieving an AUC of 0.76\\nfor pneumonia detection, marking one of the first radiologist-level AI diagnostic\\nsystems [6].\\nKeerthi et al. compared multiple deep learning architectures, including VGG16,\\nResNet50, and DenseNet121, for lung opacity detection, demonstrating that\\nDenseNet121 provided superior performance due to its dense connectivity and\\nimproved gradient flow [2]. InceptionV3, introduced by Szegedy et al., employs\\nfactorized convolutions to reduce computational cost while maintaining rich feature\\nextraction capabilities. This model has achieved up to 90% accuracy in pneumonia\\nclassification when used with transfer learning [3].\\nHowever, InceptionV3 faces challenges in capturing global dependencies and diffuse\\npatterns that may span large regions of the lung field. Vision Transformers,\\npioneered by Dosovitskiy et al., overcome this limitation by using self-attention\\nmechanisms to model long-range interactions between image patches, leading to\\nstate-of-the-art performance in various computer vision tasks, including medical\\nimaging [4]. Liu et al. improved upon the standard ViT architecture by introducing\\nthe Swin Transformer, which utilizes a hierarchical design with shifted-window\\nattention, achieving 90% accuracy in pneumonia classification while reducing\\ncomputational requirements [5]. Anthimopoulos et al. investigated CNNs for\\nclassifying interstitial lung disease patterns but highlighted the limitations posed by\\nsmall datasets and high intra-class variability [7].\\nYimer et al. employed Xception for multi-class lung disease classification, leveraging\\ndepthwise separable convolutions to reduce model size while maintaining high\\naccuracy, although the approach requires substantial GPU resources [8]. Akbulut\\nintroduced a hybrid CNN-LSTM model with attention mechanisms, enhancing\\nclassification performance for infectious lung diseases but increasing model\\ncomplexity [9]. Liu et al. identified MobileNetV2 as an effective model for real-time\\nlung disease detection, achieving low computational cost, though it struggles with\\nglobal pattern recognition due to its limited receptive field [10].\\nThese studies demonstrate the impressive performance of individual CNN,\\nInceptionV3, and Vision Transformer architectures. In this work, we will focus on\\nevaluating and comparing these three models independently—CNN, InceptionV3,\\nand ViT—to elucidate their respective strengths, weaknesses, and applicability for\\nlung disease classification from chest X‑ray images.\\nFinal Report in Course DPL302m 53 Contribution\\n3 Contribution\\nThis study provides a comprehensive benchmark of three state‑of‑the‑art deep\\nlearning architectures—standard CNN, InceptionV3, and Vision Transformer\\n(ViT)—for lung disease classification from chest X‑ray images under a unified\\nevaluation framework, reporting direct comparisons of accuracy, F1‑score, and AUC\\nfor each model.\\nTo assess the impact of transfer learning, we compare training a CNN from scratch\\nwith fine‑tuning ImageNet‑pretrained weights for InceptionV3 and ViT, quantifying\\ndifferences in convergence speed and generalization performance on a\\nmoderate‑sized dataset.\", mimetype='text/plain', start_char_idx=3263, end_char_idx=8024, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='5b2a3c41-2c59-4839-979c-e6ef79ccd13f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='dbad727a-88e3-4511-95c6-c0412697378a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ccfd030b4a272e94cb9f39497971acd28e429be54ff8a8423eeaf22ed7f6ee9d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ab17627c-d55f-412d-b25a-a478e6870fc6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b18e70a6084cc5d608453c8efb6aaa387e677b839fde5a26f6e50895405142b9')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"In this work, we will focus on\\nevaluating and comparing these three models independently—CNN, InceptionV3,\\nand ViT—to elucidate their respective strengths, weaknesses, and applicability for\\nlung disease classification from chest X‑ray images.\\nFinal Report in Course DPL302m 53 Contribution\\n3 Contribution\\nThis study provides a comprehensive benchmark of three state‑of‑the‑art deep\\nlearning architectures—standard CNN, InceptionV3, and Vision Transformer\\n(ViT)—for lung disease classification from chest X‑ray images under a unified\\nevaluation framework, reporting direct comparisons of accuracy, F1‑score, and AUC\\nfor each model.\\nTo assess the impact of transfer learning, we compare training a CNN from scratch\\nwith fine‑tuning ImageNet‑pretrained weights for InceptionV3 and ViT, quantifying\\ndifferences in convergence speed and generalization performance on a\\nmoderate‑sized dataset.\\nA standardized preprocessing and augmentation pipeline—including resizing\\n(224×224 for CNN and InceptionV3; 260×260 for ViT), pixel normalization, and\\nconsistent data augmentations (rotation, translation, shear, zoom, horizontal\\nflipping)—is applied to all three models to improve robustness and prevent\\noverfitting.\\nGrad‑CAM is integrated to generate heatmaps for each model’s predictions,\\nproviding visual explanations that highlight differences in attention regions between\\nCNN, InceptionV3, and ViT, thereby supporting clinical verification.\\nFinally, we evaluate inference time and model size on a resource‑constrained GPU,\\noffering practical deployment recommendations that balance diagnostic accuracy\\nwith computational efficiency for real‑world clinical integration.\\nFinal Report in Course DPL302m 64 Data and Models\\n4 Data and Models\\nMethodology\\nThis section details the data preparation pipeline, the three architectures\\nunder study, the training strategy, and the evaluation metrics. The approach is\\ndesigned to leverage complementary strengths of CNNs, InceptionV3 modules,\\nand Vision Transformers (ViTs) for robust multi-class lung disease\\nclassification from chest X-ray images.\\n1. Data Preparation\\nThe The dataset used in this study, sourced from Kaggle [1], comprises 3,475\\ngrayscale chest X-ray (CXR) images, categorized into three classes: Normal (1,250\\nimages, 36%), Lung Opacity (1,125 images, 32%), and Viral Pneumonia (1,100\\nimages, 32%). The images are in JPEG format with varying resolutions, reflecting\\nreal-world clinical imaging conditions. Labels are numerical: 0 for Lung Opacity, 1\\nfor Normal, and 2 for Viral Pneumonia. Visual inspection reveals distinct patterns:\\nLung Opacity cases often show localized or diffuse opacities, while Viral Pneumonia\\ncases exhibit more widespread, diffuse patterns. These subtle differences pose\\nclassification challenges, particularly when patterns overlap or are mild. Each image\\nis in JPEG format with the size 299x299. As we can see they are not plain gray\\nphotos but have RGB color mode, so the channel must be three.\\nTo standardize inputs, images are resized to 224x224 pixels for CNN and\\nInceptionV3 models, with some experiments using 260×260 pixels for the Vision\\nTransformer to accommodate its patch-based processing. Pixel intensity\\nnormalization is applied to enhance model convergence. Data augmentation,\\nimplemented via TensorFlow's ImageDataGenerator, includes random rotations (up\\nto 30°), horizontal and vertical shifts (up to 20%), shear transformations, zooming\\n(20%), and horizontal flipping to improve robustness and prevent overfitting. The\\ndataset is split into 80% training (2,780 images), 10% validation (347 images), and\\n10% testing (348 images), with stratified sampling to maintain class balance across\\nsplits (Table 1).\\nTable 1. Summarizes the dataset characteristics\\nNumber\\nClass Percentage Description\\nof Images\\nHealthy lungs, no\\nNormal 1,250 36%\\nabnormalities\\nLung Diffuse or localized\\n1,125 32%\\nOpacity opacities\\nViral Diffuse opacities, viral\\n1,100 32%\\nPneumonia infection\\nGrayscale JPEG, varying\\nTotal 3,475 100%\\nresolutions\\nFinal Report in Course DPL302m 74 Data and Models\\n2. Model Architecture\\nIn this study, we evaluate three distinct deep learning architectures—a\\nConvolutional Neural Network (CNN), InceptionV3, and a Vision Transformer\\n(ViT)—for multi‑class classification of lung diseases from chest X‑ray (CXR) images.\", mimetype='text/plain', start_char_idx=7137, end_char_idx=11449, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='ab17627c-d55f-412d-b25a-a478e6870fc6', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5b2a3c41-2c59-4839-979c-e6ef79ccd13f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f99ac509b749e9e9ab9b37c0a790da14675421f1ea8cbbcae907ee5091f153f4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8c533a68-0acb-41ca-a4cd-c0fd37b22f23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18d4274b93ee26bf9abe9d30b350aca108a0d6abc5f819d749c9b9ab252c3f4d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Table 1. Summarizes the dataset characteristics\\nNumber\\nClass Percentage Description\\nof Images\\nHealthy lungs, no\\nNormal 1,250 36%\\nabnormalities\\nLung Diffuse or localized\\n1,125 32%\\nOpacity opacities\\nViral Diffuse opacities, viral\\n1,100 32%\\nPneumonia infection\\nGrayscale JPEG, varying\\nTotal 3,475 100%\\nresolutions\\nFinal Report in Course DPL302m 74 Data and Models\\n2. Model Architecture\\nIn this study, we evaluate three distinct deep learning architectures—a\\nConvolutional Neural Network (CNN), InceptionV3, and a Vision Transformer\\n(ViT)—for multi‑class classification of lung diseases from chest X‑ray (CXR) images.\\nCNNs capture local patterns such as edges and textures; InceptionV3 enhances\\ndetection of features at multiple spatial scales through its parallel convolutional\\nbranches; ViTs provide global contextual understanding of the entire image via\\nself‑attention. Each model is trained and evaluated independently under identical\\nconditions to compare diagnostic performance, particularly in the presence of\\ncomplex or diffuse abnormalities.\\nFinal Report in Course DPL302m 84 Data and Models\\n2.1. Convolutional Neural Network (CNN)\\nFig. 2. CNN Architecture\\nThe first component is the Convolutional Neural Network (CNN) ( Figure 2). CNNs\\nare well-suited for analyzing medical images, where small local variations such as\\ntissue texture or lesion boundaries are diagnostically significant. A convolutional\\nlayer uses a set of learnable kernels to compute spatial feature maps across the\\nimage. Each convolution is followed by a non-linear activation function, typically\\nReLU, and optionally pooling operations that reduce spatial resolution and preserve\\n224×224×3\\ndominant features. For an input image 𝑋∈𝑅 , the CNN applies a sequence of\\nconvolutional layers with ReLU activations, resulting in feature maps 𝐹 :\\n𝑐𝑛𝑛\\n𝐹 = σ(𝑊 * 𝑋 + 𝑏 ) (1)\\n𝑐𝑛𝑛 𝑐𝑛𝑛 𝑐𝑛𝑛\\nwhere ∗ denotes the convolution operation, 𝑊 are the learnable convolutional\\n𝑐𝑛𝑛\\nweights, 𝑏 is the bias term, and σ represents the ReLU activation function. This\\n𝑐𝑛𝑛\\nallows the model to extract fine-grained features such as opacities, nodules, or\\ninfiltrates that are essential for distinguishing between disease types.\\nFig. 3. InceptionV3 Architecture\\nFinal Report in Course DPL302m 94 Data and Models\\n2.2. InceptionV3\\nThis architecture introduces multiple parallel convolutional branches with varying\\nkernel sizes, which process the same input and concatenate their outputs. As a\\nresult, the model can detect both small localized features and larger regional\\npatterns within the same block. For instance, in CXR images, this allows the network\\nto recognize small patchy opacities indicative of early infection as well as large\\ndiffuse lung involvement in advanced stages. The output of an Inception block, given\\nan input 𝐹 is computed as:\\n𝑖𝑛𝑐\\n𝐹 = 𝐶𝑜𝑐𝑎𝑡(𝐶𝑜𝑛𝑣 , 𝐶𝑜𝑛𝑣 , 𝐶𝑜𝑛𝑣 , 𝑃𝑜𝑜𝑙𝑖𝑛𝑔)(𝐹 ) (2)\\n𝑖𝑛𝑐 1×1 3×3 5×5 𝑐𝑛𝑛\\nwhere the different convolutional paths allow the model to learn spatial patterns at\\nvarious resolutions. Figure 3 illustrates the architecture of InceptionV3, emphasizing\\nthe factorized convolutions that reduce computational complexity while maintaining\\nrepresentational power.\\nThis multi-scale feature extraction strategy increases robustness to anatomical\\nvariations and imaging noise, which are common in real-world radiographs.\\nFig. 4. The architecture of the proposed ViT model for multi-classification lung\\ndisease prediction from Chest X-ray images.\\nFinal Report in Course DPL302m 104 Data and Models\\n2.3. Vision Transformer (ViT)\\nWhile CNNs and Inception modules excel at extracting spatial features, they are\\ninherently limited in modeling long‑range dependencies due to their local receptive\\nfields.', mimetype='text/plain', start_char_idx=10836, end_char_idx=14513, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='8c533a68-0acb-41ca-a4cd-c0fd37b22f23', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ab17627c-d55f-412d-b25a-a478e6870fc6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='b18e70a6084cc5d608453c8efb6aaa387e677b839fde5a26f6e50895405142b9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='9e98f257-af42-4fde-868f-85432daa7b08', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b1ef81d1594136b7b0974365f00a559a261e183f79bb505e69f394f3f04d3df')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Figure 3 illustrates the architecture of InceptionV3, emphasizing\\nthe factorized convolutions that reduce computational complexity while maintaining\\nrepresentational power.\\nThis multi-scale feature extraction strategy increases robustness to anatomical\\nvariations and imaging noise, which are common in real-world radiographs.\\nFig. 4. The architecture of the proposed ViT model for multi-classification lung\\ndisease prediction from Chest X-ray images.\\nFinal Report in Course DPL302m 104 Data and Models\\n2.3. Vision Transformer (ViT)\\nWhile CNNs and Inception modules excel at extracting spatial features, they are\\ninherently limited in modeling long‑range dependencies due to their local receptive\\nfields. We therefore also evaluate a Vision Transformer (ViT), which divides the\\ninput image into a sequence of non‑overlapping patches, each flattened and\\nprojected into a D‑dimensional embedding. These patch embeddings are processed\\nthrough multiple transformer encoder layers using self‑attention to model\\nrelationships between every patch, regardless of its position, enabling ViT to capture\\nglobal structures such as lung symmetry or diffuse bilateral patterns seen in viral\\n𝑁×𝐷\\npneumonia. For a sequence of embedded patches 𝑋∈𝑅 , the self-attention\\nmechanism is defined as:\\n𝑇\\n𝑄𝐾\\n𝐴𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛(𝑄, 𝐾, 𝑉)= 𝑠𝑜𝑓𝑡𝑚𝑎𝑥( ) (3)\\n𝑑\\n𝑘\\nwhere 𝑄, 𝐾 𝑎𝑛𝑑 𝑉 are the query, key, and value matrices derived from the patch\\nembeddings, and 𝑑 is the dimension of the key vector. Figure 4 illustrates the ViT\\n𝑘\\narchitecture, highlighting how images are tokenized into patches and processed\\nsequentially to model long-range dependencies.\\nThe outputs from InceptionV3 and ViT are concatenated to form a unified feature\\nrepresentation. This vector is passed through fully connected layers, culminating in\\n^\\na softmax activation function to output the predicted class probabilities 𝑦 :\\n^\\n𝑦 = 𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑊 • 𝐹 + 𝑏 ) (4)\\n𝑜𝑢𝑡 𝑣𝑖𝑡 𝑜𝑢𝑡\\nwhere 𝑊 and 𝑏 are learnable parameters and 𝐹 is the feature vector output\\n𝑜𝑢𝑡 𝑜𝑢𝑡 𝑣𝑖𝑡\\nfrom the ViT module.\\nBy training and evaluating these three models independently under identical\\nconditions, we directly compare CNN’s sensitivity to fine‑grained abnormalities,\\nInceptionV3’s multi‑scale feature detection, and ViT’s global context modeling.\\nAdditionally, Grad‑CAM is applied to both CNN and InceptionV3 to generate\\nactivation maps that highlight the regions driving each model’s predictions,\\nsupporting clinical interpretability.\\nFinal Report in Course DPL302m 114 Data and Models\\n3. Training Objectives and Loss Functions\\nThe model is optimized using the categorical cross-entropy loss function, which is\\ndefined as:\\n𝐶\\n^\\n𝐿 =− ∑ 𝑦𝑙𝑜𝑔 (𝑦) (5)\\n𝑖 𝑖\\n𝑖=1\\n^\\nwhere 𝐶 = 3 represents the number of classes, 𝑦 is the true label, and 𝑦 is the\\n𝑖 𝑖\\npredicted probability for class 𝑖.\\nTo evaluate the model performance, several metrics are computed.', mimetype='text/plain', start_char_idx=13809, end_char_idx=16645, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='9e98f257-af42-4fde-868f-85432daa7b08', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8c533a68-0acb-41ca-a4cd-c0fd37b22f23', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='18d4274b93ee26bf9abe9d30b350aca108a0d6abc5f819d749c9b9ab252c3f4d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='19a27d36-acbe-487c-a4c8-214aaba67c7d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdaddbfba2057bdb94ead46255edbc5619dbb28dc061a6a6a3a00b210daa228d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Additionally, Grad‑CAM is applied to both CNN and InceptionV3 to generate\\nactivation maps that highlight the regions driving each model’s predictions,\\nsupporting clinical interpretability.\\nFinal Report in Course DPL302m 114 Data and Models\\n3. Training Objectives and Loss Functions\\nThe model is optimized using the categorical cross-entropy loss function, which is\\ndefined as:\\n𝐶\\n^\\n𝐿 =− ∑ 𝑦𝑙𝑜𝑔 (𝑦) (5)\\n𝑖 𝑖\\n𝑖=1\\n^\\nwhere 𝐶 = 3 represents the number of classes, 𝑦 is the true label, and 𝑦 is the\\n𝑖 𝑖\\npredicted probability for class 𝑖.\\nTo evaluate the model performance, several metrics are computed. The accuracy is\\ngiven by:\\n𝑇𝑃+𝑇𝑁\\n𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 = (6)\\n𝑇𝑃+𝑇𝑁+𝐹𝑃+𝐹𝑁\\nPrecision is calculated as:\\n𝑇𝑃\\n𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 =\\n𝑇𝑃+𝐹𝑃\\nRecall is computed as:\\n𝑇𝑃\\n𝑅𝑒𝑐𝑎𝑙𝑙 = (8)\\n𝑇𝑃+𝐹𝑁\\nThe F1-Score, representing the harmonic mean of precision and recall, is:\\n𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛×𝑅𝑒𝑐𝑎𝑙𝑙\\n𝐹1 = 2× (9)\\n𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛+𝑅𝑒𝑐𝑎𝑙𝑙\\nIn addition, the Area Under the Curve (AUC) is calculated using a one-vs-rest\\nstrategy for multi-class ROC analysis, providing a robust assessment of classification\\nseparability.\\nFinal Report in Course DPL302m 125 Experiment\\n5 Experiment\\n5.1 Implementation Detail\\nFigure 5: Implementation Pipe Line\\nFigure 5 shows the workflow of each epoch, including training, validation, and\\nGrad-CAM visualization steps. The implementation is conducted in Python using\\nTensorFlow 2.13 and Keras. Training is performed on an NVIDIA RTX 3090 GPU with\\n24 GB VRAM. Transfer learning is applied by initializing InceptionV3 and ViT with\\nImageNet pre-trained weights, followed by fine-tuning on the CXR dataset. Figure\\n45depicts the entire implementation pipeline, covering data preprocessing,\\naugmentation, model training, evaluation, and interpretability analysis.\\n5.2. Result Analysis\\nThe experiments are conducted using TensorFlow 2.x on an NVIDIA RTX 3080 GPU,\\nensuring efficient training and reproducibility. The dataset is split into 80% training\\nand 20% testing, with stratification to preserve class balance among Normal, Lung\\nOpacity, and Viral Pneumonia cases.\\nTable 2. Quantitative results of baseline models and the proposed hybrid model\\nF1-scor ROC\\nMethods Accuracy Precision Recall\\ne -AUC\\nCNN 82.59% 0.83 0.82 0.82 0.95\\nInceptionV3 94.53% 0.95 0.94 0.95 0.99\\nVision 0.94 0.99\\n93.96% 0.94 0.94\\nTransformer\\nFinal Report in Course DPL302m 135 Experiment\\nTable 2 summarizes the quantitative performance of the three evaluated\\narchitectures. The baseline CNN achieves an accuracy of 82.59%, an F1‑score of\\n82%, and an AUC of 0.95, demonstrating solid sensitivity to local edge and texture\\npatterns despite its relatively simple design. InceptionV3 outperforms the CNN with\\n94.53% accuracy, 95% F1‑score, and 0.99 AUC, owing to its multi‑scale\\nconvolutional branches. The standalone Vision Transformer attains 93.96%\\naccuracy, 94% F1‑score, and 0.99 AUC, highlighting its ability to capture long‑range\\ndependencies across the lung fields.', mimetype='text/plain', start_char_idx=16051, end_char_idx=18946, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='19a27d36-acbe-487c-a4c8-214aaba67c7d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9e98f257-af42-4fde-868f-85432daa7b08', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b1ef81d1594136b7b0974365f00a559a261e183f79bb505e69f394f3f04d3df'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bc459d0a-66f7-4873-97ed-fa35d61bcf6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf2123f73aa89f03f53887b45917b2563e932c261b2c2ce9449a97d5091e66fb')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"The baseline CNN achieves an accuracy of 82.59%, an F1‑score of\\n82%, and an AUC of 0.95, demonstrating solid sensitivity to local edge and texture\\npatterns despite its relatively simple design. InceptionV3 outperforms the CNN with\\n94.53% accuracy, 95% F1‑score, and 0.99 AUC, owing to its multi‑scale\\nconvolutional branches. The standalone Vision Transformer attains 93.96%\\naccuracy, 94% F1‑score, and 0.99 AUC, highlighting its ability to capture long‑range\\ndependencies across the lung fields. These results indicate that InceptionV3\\nprovides the best overall accuracy with efficient computation, while ViT delivers\\ncomparable AUC and superior modeling of global context.\\n5.3. Qualitative Result\\nInceptionV3 Performance Analysis\\nFig. 6. Normalized Confusion Matrix of the InceptionV3\\nFinal Report in Course DPL302m 145 Experiment\\nThe confusion matrix (Figure 6) provides a detailed analysis of the classification\\nperformance. The model correctly identifies 89% of Lung Opacity cases, with 9%\\nmisclassified as Normal and 2% as Viral Pneumonia. For the Normal class, 97% are\\ncorrectly classified, while 12% are confused with Lung Opacity and 1% with Viral\\nPneumonia. Viral Pneumonia achieves the highest per-class accuracy at 97%, with\\nminimal confusion.\\nFigure 7: Grad-CAM activations for Baseline InceptionV3\\nFurthermore, Figure 7 shows Grad-CAM visualizations for the InceptionV3\\ncomponent, highlighting the lung regions most influential in the model's\\ndecision-making. These visualizations validate that the model focuses on clinically\\nrelevant features rather than irrelevant artifacts.\\nOverall, the proposed hybrid model improves quantitative metrics while\\nenhancing interpretability and clinical plausibility through attention visualization,\\nmaking it a strong candidate for real-world healthcare applications.\\nFig. 8. The qualitative analysis complements the quantitative results by providing\\nvisual and interpretive insights into the performance of the models, particularly the\\nInceptionV3 component.\\nFinal Report in Course DPL302m 155 Experiment\\nInceptionV3 Performance Visualization presents a combined visualization of the\\nInceptionV3 model's performance, including its accuracy plot, confusion matrix, and\\nROC curve. This figure reveals that InceptionV3 effectively highlights regions of\\ninterest, such as diffuse opacities in Viral Pneumonia cases, with high sensitivity, as\\nconfirmed by its 94.53% accuracy and 0.99 AUC. The confusion matrix within Fig. 8\\nshows minimal misclassifications, with only 5% error for Viral Pneumonia, aligning\\nwith its robust performance across classes. The ROC curve further supports its\\nstrong discriminative power, particularly for distinguishing between Normal and\\npathological cases.\\nThe Grad-CAM visualizations (Fig. 7) for InceptionV3 provide additional\\nqualitative evidence of model reliability. These heatmaps consistently focus on\\nclinically significant areas, such as the lung fields, rather than irrelevant background\\nregions, enhancing trust in the model's diagnostic decisions. For instance, in Viral\\nPneumonia cases, Grad-CAM activations emphasize diffuse bilateral patterns, which\\ncorrelate with radiological findings. This interpretability is crucial for clinical\\nadoption, as it allows radiologists to verify the model's focus and align it with expert\\ndiagnoses. The qualitative insights suggest that while InceptionV3 excels\\nindividually, its integration into the hybrid model balances its strengths with the\\nglobal context provided by ViT, offering a comprehensive diagnostic tool for lung\\ndisease classification.\\nCNN Performance Analysis\\nAccuracy and Loss Curves\\nFigure 9. CNN Accuracy and Loss Curves over 22 Epochs\\nThe CNN model demonstrated a gradual improvement in training accuracy,\\nincreasing from approximately 56% to 82% over the span of 22 epochs. As\\nillustrated in Figure 9, the validation accuracy ranged between 74% and 84%,\\nindicating relatively stable learning but moderate generalization capability. Training\\nloss steadily decreased, while validation loss fluctuated slightly, suggesting that the\\nmodel experienced minor overfitting after a certain point.\\nFinal Report in Course DPL302m 165 Experiment\\nConfusion Matrix\\nFigure 10. CNN Confusion Matrix on Test Set\\nAs shown in Figure 10, the CNN achieved excellent results in classifying Viral\\nPneumonia, with 95% of samples correctly identified. However, the model faced\\nchallenges in distinguishing Lung Opacity from Normal cases.\", mimetype='text/plain', start_char_idx=18451, end_char_idx=22911, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='bc459d0a-66f7-4873-97ed-fa35d61bcf6f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='19a27d36-acbe-487c-a4c8-214aaba67c7d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bdaddbfba2057bdb94ead46255edbc5619dbb28dc061a6a6a3a00b210daa228d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e232f44d-797b-489b-a0a5-e8db1d6b506a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8928cd6471ca2f3a214d1407202a1a07e585d9a3eade2146e9361a04409b9db9')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"CNN Performance Analysis\\nAccuracy and Loss Curves\\nFigure 9. CNN Accuracy and Loss Curves over 22 Epochs\\nThe CNN model demonstrated a gradual improvement in training accuracy,\\nincreasing from approximately 56% to 82% over the span of 22 epochs. As\\nillustrated in Figure 9, the validation accuracy ranged between 74% and 84%,\\nindicating relatively stable learning but moderate generalization capability. Training\\nloss steadily decreased, while validation loss fluctuated slightly, suggesting that the\\nmodel experienced minor overfitting after a certain point.\\nFinal Report in Course DPL302m 165 Experiment\\nConfusion Matrix\\nFigure 10. CNN Confusion Matrix on Test Set\\nAs shown in Figure 10, the CNN achieved excellent results in classifying Viral\\nPneumonia, with 95% of samples correctly identified. However, the model faced\\nchallenges in distinguishing Lung Opacity from Normal cases. Around 26% of Lung\\nOpacity cases were misclassified as Normal, while 14% of Normal cases were\\npredicted as Lung Opacity. This implies that CNN's limited receptive field might\\nhinder its ability to capture diffuse or ambiguous regions.\\nROC Curve\\nThe ROC analysis (Figure 11) highlights that the model performed best for Viral Pneumonia\\n(AUC = 0.99), followed by Lung Opacity (0.94) and Normal (0.93). These metrics confirm that\\nCNN is especially effective at identifying well-defined pathologies like Viral Pneumonia but\\nstruggles with borderline or overlapping patterns.\\nFigure 11. CNN ROC Curves by Class\\nFinal Report in Course DPL302m 175 Experiment\\nVision Transformer (ViT) Performance Analysis\\nAccuracy and Loss Curves\\nThe ViT model reached ~99% training accuracy within just 10 epochs, as shown\\nin Figure 15, indicating very fast learning. Validation accuracy stabilized around\\n94.5%, which is competitive with InceptionV3. However, a slight rise in validation\\nloss after epoch 4 suggests potential overfitting due to the model's high complexity\\nand sensitivity to noise in the data.\\nFigure 12. ViT Accuracy and Loss Performance\\nConfusion Matrix\\nFigure 13 illustrates the model’s per-class performance:\\n● 91% accuracy for Lung Opacity (205/225)\\n● 92% accuracy for Normal (229/250)\\n● 99.5% accuracy for Viral Pneumonia (219/220)\\nThese results underscore ViT’s strength in capturing global patterns, which is\\nespecially useful in complex cases like Viral Pneumonia where diffuse abnormalities\\nmay span both lungs.\\nFigure 13. ViT Confusion Matrix\\nFinal Report in Course DPL302m 185 Experiment\\nROC Curve\\nThe ROC curves in Figure 14 show outstanding classification ability. The AUC\\nscores for Lung Opacity and Normal are both 0.99, while Viral Pneumonia reaches a\\nperfect 1.00, reflecting ViT's exceptional pattern recognition across long-range\\nspatial features.\\nFigure 14. ViT ROC Curves across Three Classes\\nComparative Performance Visualization\\nTo further illustrate the differences in classification performance between the\\nmodels, we present side-by-side bar charts comparing their ROC AUC, Accuracy, and\\nValidation Loss.\\nROC AUC Comparison\\nAs shown in Figure 15, the Vision Transformer (ViT) achieves a perfect AUC of\\n1.00, outperforming InceptionV3 (0.99) and CNN (0.95). This metric highlights the\\nsuperior ability of ViT and InceptionV3 to distinguish between lung disease classes,\\nespecially in imbalanced or complex patterns.\\nFigure 15. ROC AUC Comparison among CNN, InceptionV3, and Vision\\nTransformer\\nFinal Report in Course DPL302m 195 Experiment\\nAccuracy Comparison\\nIn Figure 16, InceptionV3 records the highest test accuracy at 94.53%, followed\\nclosely by ViT (93.96%), both significantly surpassing CNN (82.59%). This\\ndemonstrates the advantage of deeper, multi-scale architectures and global attention\\nmechanisms over traditional CNNs in chest X-ray interpretation.\\nFigure 16. Accuracy Comparison across Models on Test Dataset\\nValidation Loss Comparison\\nFigure 17 illustrates the average final validation loss for each model. InceptionV3\\nachieves the lowest loss (~0.15), indicating high generalization ability and robust\\nlearning. ViT performs similarly well (~0.20), whereas CNN exhibits the highest\\nvalidation loss (~0.40), which correlates with its comparatively lower accuracy and\\noverfitting signs.\\nFigure 17.\", mimetype='text/plain', start_char_idx=22029, end_char_idx=26244, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='e232f44d-797b-489b-a0a5-e8db1d6b506a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='bc459d0a-66f7-4873-97ed-fa35d61bcf6f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bf2123f73aa89f03f53887b45917b2563e932c261b2c2ce9449a97d5091e66fb'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b0fff956-0f33-49e3-a685-d6231b67bfa2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb489727478b51f3ba21faef26b0f05e3d6756739f13127169bb2c0d10e04e72')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='This\\ndemonstrates the advantage of deeper, multi-scale architectures and global attention\\nmechanisms over traditional CNNs in chest X-ray interpretation.\\nFigure 16. Accuracy Comparison across Models on Test Dataset\\nValidation Loss Comparison\\nFigure 17 illustrates the average final validation loss for each model. InceptionV3\\nachieves the lowest loss (~0.15), indicating high generalization ability and robust\\nlearning. ViT performs similarly well (~0.20), whereas CNN exhibits the highest\\nvalidation loss (~0.40), which correlates with its comparatively lower accuracy and\\noverfitting signs.\\nFigure 17. Final Validation Loss across CNN, InceptionV3, and ViT\\nFinal Report in Course DPL302m 205 Experiment\\n5.4. Comparative Evaluation with Existing Methods\\nTo contextualize the performance of our hybrid CNN–InceptionV3–ViT model, we\\nconducted a comparative analysis with recent studies that utilized the same Kaggle\\nChest X-ray dataset consisting of three classes: Normal, Lung Opacity, and Viral\\nPneumonia. Specifically, we selected three representative works: Akinboyo [16], Ifty\\net al. [17], and Sugianto [18], all of which either publicly released their code or\\nclearly stated dataset usage and class structure.\\nQuantitative and Qualitative Comparison\\nTable 7. Comparison of Multi-Class Lung Disease Classification Methods Using the\\nKaggle Chest X-ray Dataset [1]\\nMethods Accuracy F1-Score AUC\\nDataset\\nKaggle\\nResNet-18 92.00% 91.6% –\\n(3-class)\\nKaggle\\nXception +XAI Ensemble 92.06 – –\\n(3-class)\\nKaggle\\nCustom CNN 83.59% 82% 0.95\\n(3-class)\\nKaggle\\nInceptionv3 94.53% 95% 0.99\\n(3-class)\\nKaggle\\nViT 93.96% 94% 0.99\\n(3-class)\\nIn the first study, Akinboyo [16] employed a ResNet-18 model fine-tuned via\\ntransfer learning on the same Kaggle dataset. Their model achieved an accuracy of\\n92.00% and an F1-score of 91.6%, placing it in the same performance tier as ours.\\nHowever, their approach did not include any interpretability tools, which limits\\nclinical trust. In contrast, our best model is InceptionV3 attained a comparable\\naccuracy of 94.53%, an F1-score of 95%, and an AUC of 0.99, while also\\nincorporating Grad-CAM visualization to highlight radiologically relevant regions.\\nThis makes our model more suitable for explainable AI applications in healthcare.\\nFinal Report in Course DPL302m 215 Experiment\\nThe second work, by Ifty et al. [17], combined several Xception-based CNNs into\\nan ensemble model and added explainable AI (XAI) techniques. Their framework\\nachieved a notably higher accuracy of 92.06%. However, their ensemble approach\\ninvolves greater computational cost, longer inference time, and increased\\ndeployment complexity—factors that may hinder real-world clinical integration. Our\\nmodel, by contrast, uses a single unified hybrid pipeline and still delivers\\ncompetitive performance, striking a more efficient balance between accuracy,\\ntransparency, and deployment readiness.\\nFinal Remarks\\nThe best model - InceptionV3 stands out not only it claims the highest accuracy,\\nbut also it delivers the most balanced and practical solution for real-world use:\\n● Highest Accuracy: 94.53% test accuracy, 95% F1-score.\\n● Explainability: Built-in Grad-CAM for clinical transparency.\\n● Efficiency: Single hybrid model (not ensemble), optimized for fast inference.\\n● Generalizability: Strong class-wise performance even with class imbalance\\n(e.g., 95% for Viral Pneumonia, 86% for Normal, 80% for Lung Opacity).\\nBy integrating local (CNN), multi-scale (InceptionV3), and global attention (ViT)\\nwith robust preprocessing data augmentation, our pipeline provides a practical,\\ninterpretable, and reproducible approach. This positions our framework as the\\nmost clinically viable solution among recent works using the same dataset.\\nFinal Report in Course DPL302m 226 Conclusion and Perspectives\\n6 Conclusion and Perspectives\\nThis paper evaluates three deep learning approaches—standard CNN, InceptionV3,\\nand Vision Transformer (ViT)—for lung disease classification from chest X‑ray\\nimages under a unified framework. Using a balanced Kaggle dataset, we directly\\ncompare each model’s accuracy, F1‑score, and AUC.', mimetype='text/plain', start_char_idx=25641, end_char_idx=29751, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='b0fff956-0f33-49e3-a685-d6231b67bfa2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e232f44d-797b-489b-a0a5-e8db1d6b506a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8928cd6471ca2f3a214d1407202a1a07e585d9a3eade2146e9361a04409b9db9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='764ddbc6-1a2c-45bf-93fa-f99e29623f8a', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f5f5452f1ddf0b550cee36cedbeaa3415d24cfd1052c371e133f77996d70271b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='● Generalizability: Strong class-wise performance even with class imbalance\\n(e.g., 95% for Viral Pneumonia, 86% for Normal, 80% for Lung Opacity).\\nBy integrating local (CNN), multi-scale (InceptionV3), and global attention (ViT)\\nwith robust preprocessing data augmentation, our pipeline provides a practical,\\ninterpretable, and reproducible approach. This positions our framework as the\\nmost clinically viable solution among recent works using the same dataset.\\nFinal Report in Course DPL302m 226 Conclusion and Perspectives\\n6 Conclusion and Perspectives\\nThis paper evaluates three deep learning approaches—standard CNN, InceptionV3,\\nand Vision Transformer (ViT)—for lung disease classification from chest X‑ray\\nimages under a unified framework. Using a balanced Kaggle dataset, we directly\\ncompare each model’s accuracy, F1‑score, and AUC. InceptionV3 delivers the highest\\noverall accuracy, ViT demonstrates strong generalization and global context\\nmodeling, and the CNN baseline reliably detects fine‑grained abnormalities.\\nApplying Grad‑CAM interpretability to CNN and InceptionV3 yields clinically\\nmeaningful heatmaps that enhance transparency and trust.\\nFuture work will extend this evaluation to additional lung conditions, explore\\nensemble and hybrid strategies to combine individual strengths, and validate\\nperformance on larger, multi‑institutional datasets to ensure robustness and\\nreal‑world clinical applicability.\\nFinal Report in Course DPL302m 23References\\n[1] F. Mehrparvar, Lung Disease Detection Using Chest X-ray Dataset, Kaggle, 2022.\\nAvailable: https://www.kaggle.com/datasets/fatemehmehrparvar/lung-disease\\n[2] G. Keerthi et al., “A Comparative Study of Deep Learning Models in Detection of Lung\\nOpacity,” Journal of Smart Computing and Cognitive Informatics, 2023.\\n[3] C. Szegedy et al., “Going Deeper with Convolutions,” IEEE CVPR, 2015.\\n[4] A. Dosovitskiy et al., “An Image is Worth 16x16 Words: Transformers for Image\\nRecognition at Scale,” ICLR, 2021.\\n[5] Z. Liu et al., “Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,”\\nICCV, 2021.\\n[6] P. Rajpurkar et al., “CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with\\nDeep Learning,” arXiv preprint arXiv:1711.05225, 2017.\\n[7] M. Anthimopoulos et al., “Convolutional Neural Networks for Lung Pattern Classification in\\nInterstitial Lung Diseases,” IEEE Transactions on Medical Imaging, vol. 35, no. 5, pp.\\n1207–1216, 2016.\\n[8] F. S. Yimer et al., “Multiple Lung Diseases Classification from Chest X-Ray Images using\\nDeep Learning Approach,” International Journal of Advanced Trends in Computer Science\\nand Engineering, vol. 10, no. 5, 2021.\\n[9] Y. Akbulut, “Automated Pneumonia-Based Lung Diseases Classification with Robust\\nTechnique Based on a Customized Deep Learning Approach,” Diagnostics, vol. 13, no. 2,\\n2023.\\n[10] X. Liu et al., “Lung Disease Classification Using MobileNet-Lung with Attention\\nMechanism,” IEEE ICSECE, 2024.\\n[11] T. Rahman, A. Khandakar, M.A.Kadir, K. R. Islam, K. F. Islam, Z. B. Mahbub, M. A. Ayari,\\nand M.E.H.Chowdhury,“ReliableTuberculosisDetectionusingChestX-raywithDeepLearning,\\nSegmentation and Visualization,” IEEE Access, vol. 8, pp. 191586–191601, 2020.\\n[12] S. Jaeger, S. Candemir, S. Antani, Y.-X. J. Wáng, P.-X. Lu, and G. Thoma, “Two public chest\\nX-ray datasets for computer-aided screening of pulmonary diseases,” Quantitative Imaging\\nin Medicine and Surgery, vol. 4, no. 6, p. 475, 2014.\\n[13] B. P. Health, “Belarus Tuberculosis Portal,” 2020. Available: http://tuberculosis.by/.\\n[Ac cessed: 09-June-2020]\\n[14] NIAID TBPortal Program Dataset,2020. Available:\\nhttps://tbportals.niaid.nih.gov/download\\n[15] Kaggle, “RSNA Pneumonia Detection Challenge,” 2020.', mimetype='text/plain', start_char_idx=28911, end_char_idx=32617, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='764ddbc6-1a2c-45bf-93fa-f99e29623f8a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='574015b3-f312-4f8f-919a-57d36d177439', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5006f31fb13c12caa3bfa52bed20b199f8f2b4e6b6dfe46f6a0fd2e611eaefc7'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b0fff956-0f33-49e3-a685-d6231b67bfa2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb489727478b51f3ba21faef26b0f05e3d6756739f13127169bb2c0d10e04e72')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='8, pp. 191586–191601, 2020.\\n[12] S. Jaeger, S. Candemir, S. Antani, Y.-X. J. Wáng, P.-X. Lu, and G. Thoma, “Two public chest\\nX-ray datasets for computer-aided screening of pulmonary diseases,” Quantitative Imaging\\nin Medicine and Surgery, vol. 4, no. 6, p. 475, 2014.\\n[13] B. P. Health, “Belarus Tuberculosis Portal,” 2020. Available: http://tuberculosis.by/.\\n[Ac cessed: 09-June-2020]\\n[14] NIAID TBPortal Program Dataset,2020. Available:\\nhttps://tbportals.niaid.nih.gov/download\\n[15] Kaggle, “RSNA Pneumonia Detection Challenge,” 2020. Available:\\nhttps://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data [Accessed:\\n09-June 2020]\\n[16] [16] R. Akinboyo, “Lung Disease Multiclass CNN Classifier,” GitHub, 2023. [Online].\\nAvailable: https://github.com/rachealakinboyo/lung-disease-multiclass-cnn-classifier\\n[17] T. T. Ifty, M. Moni, R. Rahman, and A. M. M. Rahman, “Explainable Lung Disease\\nClassification Using Deep CNNs: A Comparative Study,” arXiv preprint, arXiv:2404.11428,\\n2024. [Online]. Available: https://arxiv.org/abs/2404.11428\\n[18] D. W. Sugianto, “Hybrid Vision Transformer-CNN for Lung X-Ray Image Classification,”\\nGitHub Repository, 2024. [Online]. Available:\\nhttps://github.com/dwisugianto/Hybrid-Vision-Transformer-CNN-for-Lung-X-Ray-Image-\\nClassification\\n24', mimetype='text/plain', start_char_idx=32081, end_char_idx=33361, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]\n"
          ]
        }
      ],
      "source": [
        "print(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "đáng ra cái này xài được nhưng mạng lỏ hay lỗi gì đó mà cứ timeout, nên chuyển sang model offline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei2ZClZMxbzt",
        "outputId": "d8ef6aee-0ff6-4428-ff17-87beb6e787ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "ename": "ReadTimeout",
          "evalue": "(ReadTimeoutError(\"HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: eba1c894-fced-4a0c-bfb0-f882bfb13e02)')",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connection.py:969\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    967\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\util\\ssl_.py:480\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    478\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\util\\ssl_.py:524\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1041\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1040\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1319\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1318\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[31mTimeoutError\u001b[39m: _ssl.c:993: The handshake operation timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
            "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out. (read timeout=10)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model.encode([text]).tolist()[\u001b[32m0\u001b[39m]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Thay đổi model_name thành one-of-the-above\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m embed_model = \u001b[43mHFEmbeddingModel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Nếu bạn đã cài hf_xet hoặc hf_transfer, sẽ fallback nhanh hơn cho file lớn\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# pip install \"huggingface_hub[hf_xet]\" hf_transfer\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mHFEmbeddingModel.__init__\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Chọn model nhẹ hơn\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28mself\u001b[39m._model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:327\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    309\u001b[39m has_modules = is_sentence_transformer_model(\n\u001b[32m    310\u001b[39m     model_name_or_path,\n\u001b[32m    311\u001b[39m     token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     local_files_only=local_files_only,\n\u001b[32m    315\u001b[39m )\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    317\u001b[39m     has_modules\n\u001b[32m    318\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_model_type(\n\u001b[32m   (...)\u001b[39m\u001b[32m    325\u001b[39m     == \u001b[38;5;28mself\u001b[39m._model_config[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    326\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    339\u001b[39m     modules = \u001b[38;5;28mself\u001b[39m._load_auto_model(\n\u001b[32m    340\u001b[39m         model_name_or_path,\n\u001b[32m    341\u001b[39m         token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         has_modules=has_modules,\n\u001b[32m    350\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:2253\u001b[39m, in \u001b[36mSentenceTransformer._load_sbert_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n\u001b[32m   2248\u001b[39m         module = module_class.load(local_path)\n\u001b[32m   2250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2251\u001b[39m     \u001b[38;5;66;03m# Newer modules that support the new loading method are loaded with the new style\u001b[39;00m\n\u001b[32m   2252\u001b[39m     \u001b[38;5;66;03m# i.e. with many keyword arguments that can optionally be used by the modules\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2253\u001b[39m     module = \u001b[43mmodule_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2255\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Loading-specific keyword arguments\u001b[39;49;00m\n\u001b[32m   2256\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2261\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Module-specific keyword arguments\u001b[39;49;00m\n\u001b[32m   2262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2269\u001b[39m modules[module_config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]] = module\n\u001b[32m   2270\u001b[39m module_kwargs[module_config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]] = module_config.get(\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:338\u001b[39m, in \u001b[36mTransformer.load\u001b[39m\u001b[34m(cls, model_name_or_path, subfolder, token, cache_folder, revision, local_files_only, trust_remote_code, model_kwargs, tokenizer_kwargs, config_kwargs, backend, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    309\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m     **kwargs,\n\u001b[32m    324\u001b[39m ) -> Self:\n\u001b[32m    325\u001b[39m     init_kwargs = \u001b[38;5;28mcls\u001b[39m._load_init_kwargs(\n\u001b[32m    326\u001b[39m         model_name_or_path=model_name_or_path,\n\u001b[32m    327\u001b[39m         subfolder=subfolder,\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m         backend=backend,\n\u001b[32m    337\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:87\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n\u001b[32m     84\u001b[39m     config_args = {}\n\u001b[32m     86\u001b[39m config, is_peft_model = \u001b[38;5;28mself\u001b[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_peft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[32m     90\u001b[39m     tokenizer_args[\u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m] = max_seq_length\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:185\u001b[39m, in \u001b[36mTransformer._load_model\u001b[39m\u001b[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[39m\n\u001b[32m    183\u001b[39m         \u001b[38;5;28mself\u001b[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28mself\u001b[39m.auto_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend == \u001b[33m\"\u001b[39m\u001b[33monnx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28mself\u001b[39m.auto_model = load_onnx_model(\n\u001b[32m    190\u001b[39m         model_name_or_path=model_name_or_path,\n\u001b[32m    191\u001b[39m         config=config,\n\u001b[32m    192\u001b[39m         task_name=\u001b[33m\"\u001b[39m\u001b[33mfeature-extraction\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    193\u001b[39m         **model_args,\n\u001b[32m    194\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\modeling_utils.py:288\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    290\u001b[39m     torch.set_default_dtype(old_dtype)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\modeling_utils.py:5027\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5018\u001b[39m     gguf_file\n\u001b[32m   5019\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5020\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   5021\u001b[39m ):\n\u001b[32m   5022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   5023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5025\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m5027\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5029\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5034\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5035\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5036\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5038\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5039\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5040\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5041\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   5044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5045\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5047\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5048\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\modeling_utils.py:1150\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m   1137\u001b[39m     cached_file_kwargs = {\n\u001b[32m   1138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcache_dir\u001b[39m\u001b[33m\"\u001b[39m: cache_dir,\n\u001b[32m   1139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mforce_download\u001b[39m\u001b[33m\"\u001b[39m: force_download,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m: commit_hash,\n\u001b[32m   1149\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1152\u001b[39m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[32m   1153\u001b[39m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[32m   1154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[32m   1155\u001b[39m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\utils\\hub.py:321\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    264\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    265\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    266\u001b[39m     **kwargs,\n\u001b[32m    267\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    270\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\utils\\hub.py:566\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    563\u001b[39m     \u001b[38;5;66;03m# Any other Exception type should now be re-raised, in order to provide helpful error messages and break the execution flow\u001b[39;00m\n\u001b[32m    564\u001b[39m     \u001b[38;5;66;03m# (EntryNotFoundError will be treated outside this block and correctly re-raised if needed)\u001b[39;00m\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    568\u001b[39m resolved_files = [\n\u001b[32m    569\u001b[39m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    570\u001b[39m ]\n\u001b[32m    571\u001b[39m \u001b[38;5;66;03m# If there are any missing file and the flag is active, raise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\utils\\hub.py:478\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    477\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    493\u001b[39m         snapshot_download(\n\u001b[32m    494\u001b[39m             path_or_repo_id,\n\u001b[32m    495\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    504\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    505\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:1171\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1184\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:1738\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1731\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n\u001b[32m   1732\u001b[39m             logger.warning(\n\u001b[32m   1733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1735\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1736\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1738\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1747\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1748\u001b[39m _chmod_and_move(incomplete_path, destination_path)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:426\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    420\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    421\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    422\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file is too large to be downloaded using the regular download method. Use `hf_transfer` or `hf_xet` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    423\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Try `pip install hf_transfer` or `pip install hf_xet`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHF_HUB_DOWNLOAD_TIMEOUT\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m hf_raise_for_status(r)\n\u001b[32m    431\u001b[39m total: Optional[\u001b[38;5;28mint\u001b[39m] = _get_file_length_from_http_response(r)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m429\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:310\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\sessions.py:724\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[32m    722\u001b[39m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[32m    723\u001b[39m     gen = \u001b[38;5;28mself\u001b[39m.resolve_redirects(r, request, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     history = \u001b[43m[\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    726\u001b[39m     history = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\sessions.py:265\u001b[39m, in \u001b[36mSessionRedirectMixin.resolve_redirects\u001b[39m\u001b[34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m.cookies, prepared_request, resp.raw)\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:96\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\adapters.py:690\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    688\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
            "\u001b[31mReadTimeout\u001b[39m: (ReadTimeoutError(\"HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: eba1c894-fced-4a0c-bfb0-f882bfb13e02)')"
          ]
        }
      ],
      "source": [
        "# from sentence_transformers import SentenceTransformer\n",
        "# # Thay thế phần embed_model của bạn\n",
        "# import os\n",
        "\n",
        "# # Tăng thời gian chờ download lên 5 phút\n",
        "# os.environ[\"HF_HUB_DOWNLOAD_TIMEOUT\"] = \"300\"\n",
        "# class HFEmbeddingModel:\n",
        "#     def __init__(self, model_name: str):\n",
        "#         # Chọn model nhẹ hơn\n",
        "#         self._model = SentenceTransformer(model_name)\n",
        "#     def embed(self, texts: list[str]) -> list[list[float]]:\n",
        "#         return self._model.encode(texts).tolist()\n",
        "#     def embed_query(self, text: str) -> list[float]:\n",
        "#         return self._model.encode([text]).tolist()[0]\n",
        "\n",
        "# # Thay đổi model_name thành one-of-the-above\n",
        "# embed_model = HFEmbeddingModel(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "\n",
        "# Nếu bạn đã cài hf_xet hoặc hf_transfer, sẽ fallback nhanh hơn cho file lớn\n",
        "# pip install \"huggingface_hub[hf_xet]\" hf_transfer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# import torch\n",
        "\n",
        "# os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
        "# model_path = \"D:/Project_self/models/all-MiniLM-L6-v2\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "# model     = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
        "# model.eval()\n",
        "\n",
        "# def embedding_fn(texts: list[str]) -> list[list[float]]:\n",
        "#     enc = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "#     with torch.no_grad():\n",
        "#         out = model(**enc, return_dict=True)\n",
        "#     # Lấy CLS token embedding\n",
        "#     return out.last_hidden_state[:, 0, :].cpu().numpy().tolist()\n",
        "\n",
        "# def embed_query_fn(text: str) -> list[float]:\n",
        "#     return embedding_fn([text])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "ename": "ReadTimeout",
          "evalue": "(ReadTimeoutError(\"HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: eba1c894-fced-4a0c-bfb0-f882bfb13e02)')",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n",
            "\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n",
            "\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m    788\u001b[39m server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    807\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    808\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connection.py:969\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n",
            "\u001b[32m    967\u001b[39m         server_hostname = normalized\n",
            "\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    980\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\util\\ssl_.py:480\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n",
            "\u001b[32m    478\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n",
            "\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\util\\ssl_.py:524\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n",
            "\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n",
            "\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n",
            "\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
            "\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
            "\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
            "\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
            "\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n",
            "\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n",
            "\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1041\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n",
            "\u001b[32m   1040\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1319\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n",
            "\u001b[32m   1318\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m   1320\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\n",
            "\u001b[31mTimeoutError\u001b[39m: _ssl.c:993: The handshake operation timed out\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n",
            "\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n",
            "\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n",
            "\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    844\u001b[39m retries.sleep()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n",
            "\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n",
            "\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n",
            "\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n",
            "\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
            "\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n",
            "\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n",
            "\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n",
            "\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n",
            "\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n",
            "\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n",
            "\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\urllib3\\connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n",
            "\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n",
            "\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n",
            "\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
            "\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
            "\n",
            "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 17\u001b[39m\n",
            "\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model.encode([text]).tolist()[\u001b[32m0\u001b[39m]\n",
            "\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Thay đổi model_name thành one-of-the-above\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m embed_model = \u001b[43mHFEmbeddingModel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Nếu bạn đã cài hf_xet hoặc hf_transfer, sẽ fallback nhanh hơn cho file lớn\u001b[39;00m\n",
            "\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# pip install \"huggingface_hub[hf_xet]\" hf_transfer\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mHFEmbeddingModel.__init__\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n",
            "\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m):\n",
            "\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Chọn model nhẹ hơn\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28mself\u001b[39m._model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:327\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n",
            "\u001b[32m    309\u001b[39m has_modules = is_sentence_transformer_model(\n",
            "\u001b[32m    310\u001b[39m     model_name_or_path,\n",
            "\u001b[32m    311\u001b[39m     token,\n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     local_files_only=local_files_only,\n",
            "\u001b[32m    315\u001b[39m )\n",
            "\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n",
            "\u001b[32m    317\u001b[39m     has_modules\n",
            "\u001b[32m    318\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_model_type(\n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m    325\u001b[39m     == \u001b[38;5;28mself\u001b[39m._model_config[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[32m    326\u001b[39m ):\n",
            "\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    338\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[32m    339\u001b[39m     modules = \u001b[38;5;28mself\u001b[39m._load_auto_model(\n",
            "\u001b[32m    340\u001b[39m         model_name_or_path,\n",
            "\u001b[32m    341\u001b[39m         token=token,\n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         has_modules=has_modules,\n",
            "\u001b[32m    350\u001b[39m     )\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:2253\u001b[39m, in \u001b[36mSentenceTransformer._load_sbert_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n",
            "\u001b[32m   2248\u001b[39m         module = module_class.load(local_path)\n",
            "\u001b[32m   2250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[32m   2251\u001b[39m     \u001b[38;5;66;03m# Newer modules that support the new loading method are loaded with the new style\u001b[39;00m\n",
            "\u001b[32m   2252\u001b[39m     \u001b[38;5;66;03m# i.e. with many keyword arguments that can optionally be used by the modules\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m2253\u001b[39m     module = \u001b[43mmodule_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m   2254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2255\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Loading-specific keyword arguments\u001b[39;49;00m\n",
            "\u001b[32m   2256\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2261\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Module-specific keyword arguments\u001b[39;49;00m\n",
            "\u001b[32m   2262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   2267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m   2269\u001b[39m modules[module_config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]] = module\n",
            "\u001b[32m   2270\u001b[39m module_kwargs[module_config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]] = module_config.get(\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:338\u001b[39m, in \u001b[36mTransformer.load\u001b[39m\u001b[34m(cls, model_name_or_path, subfolder, token, cache_folder, revision, local_files_only, trust_remote_code, model_kwargs, tokenizer_kwargs, config_kwargs, backend, **kwargs)\u001b[39m\n",
            "\u001b[32m    307\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n",
            "\u001b[32m    308\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n",
            "\u001b[32m    309\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m     **kwargs,\n",
            "\u001b[32m    324\u001b[39m ) -> Self:\n",
            "\u001b[32m    325\u001b[39m     init_kwargs = \u001b[38;5;28mcls\u001b[39m._load_init_kwargs(\n",
            "\u001b[32m    326\u001b[39m         model_name_or_path=model_name_or_path,\n",
            "\u001b[32m    327\u001b[39m         subfolder=subfolder,\n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m         backend=backend,\n",
            "\u001b[32m    337\u001b[39m     )\n",
            "\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:87\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n",
            "\u001b[32m     84\u001b[39m     config_args = {}\n",
            "\u001b[32m     86\u001b[39m config, is_peft_model = \u001b[38;5;28mself\u001b[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n",
            "\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_peft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n",
            "\u001b[32m     90\u001b[39m     tokenizer_args[\u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m] = max_seq_length\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:185\u001b[39m, in \u001b[36mTransformer._load_model\u001b[39m\u001b[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[39m\n",
            "\u001b[32m    183\u001b[39m         \u001b[38;5;28mself\u001b[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n",
            "\u001b[32m    184\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28mself\u001b[39m.auto_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\n",
            "\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    188\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend == \u001b[33m\"\u001b[39m\u001b[33monnx\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[32m    189\u001b[39m     \u001b[38;5;28mself\u001b[39m.auto_model = load_onnx_model(\n",
            "\u001b[32m    190\u001b[39m         model_name_or_path=model_name_or_path,\n",
            "\u001b[32m    191\u001b[39m         config=config,\n",
            "\u001b[32m    192\u001b[39m         task_name=\u001b[33m\"\u001b[39m\u001b[33mfeature-extraction\u001b[39m\u001b[33m\"\u001b[39m,\n",
            "\u001b[32m    193\u001b[39m         **model_args,\n",
            "\u001b[32m    194\u001b[39m     )\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n",
            "\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
            "\u001b[32m    603\u001b[39m         config = config.get_text_config()\n",
            "\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n",
            "\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
            "\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m    610\u001b[39m )\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\modeling_utils.py:288\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
            "\u001b[32m    286\u001b[39m old_dtype = torch.get_default_dtype()\n",
            "\u001b[32m    287\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    289\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[32m    290\u001b[39m     torch.set_default_dtype(old_dtype)\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\modeling_utils.py:5027\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n",
            "\u001b[32m   5017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n",
            "\u001b[32m   5018\u001b[39m     gguf_file\n",
            "\u001b[32m   5019\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[32m   5020\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n",
            "\u001b[32m   5021\u001b[39m ):\n",
            "\u001b[32m   5022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n",
            "\u001b[32m   5023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m   5024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m   5025\u001b[39m     )\n",
            "\u001b[32m-> \u001b[39m\u001b[32m5027\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m   5028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5029\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5034\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5035\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5036\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5038\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5039\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5040\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5041\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   5045\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m   5047\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[32m   5048\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\modeling_utils.py:1150\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n",
            "\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[32m   1136\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n",
            "\u001b[32m   1137\u001b[39m     cached_file_kwargs = {\n",
            "\u001b[32m   1138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcache_dir\u001b[39m\u001b[33m\"\u001b[39m: cache_dir,\n",
            "\u001b[32m   1139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mforce_download\u001b[39m\u001b[33m\"\u001b[39m: force_download,\n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m: commit_hash,\n",
            "\u001b[32m   1149\u001b[39m     }\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m   1152\u001b[39m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n",
            "\u001b[32m   1153\u001b[39m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n",
            "\u001b[32m   1154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(SAFE_WEIGHTS_NAME, variant):\n",
            "\u001b[32m   1155\u001b[39m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\utils\\hub.py:321\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n",
            "\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n",
            "\u001b[32m    264\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n",
            "\u001b[32m    265\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n",
            "\u001b[32m    266\u001b[39m     **kwargs,\n",
            "\u001b[32m    267\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n",
            "\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n",
            "\u001b[32m    269\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n",
            "\u001b[32m    270\u001b[39m \n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n",
            "\u001b[32m    320\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    322\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n",
            "\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\utils\\hub.py:566\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n",
            "\u001b[32m    563\u001b[39m     \u001b[38;5;66;03m# Any other Exception type should now be re-raised, in order to provide helpful error messages and break the execution flow\u001b[39;00m\n",
            "\u001b[32m    564\u001b[39m     \u001b[38;5;66;03m# (EntryNotFoundError will be treated outside this block and correctly re-raised if needed)\u001b[39;00m\n",
            "\u001b[32m    565\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n",
            "\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[32m    568\u001b[39m resolved_files = [\n",
            "\u001b[32m    569\u001b[39m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n",
            "\u001b[32m    570\u001b[39m ]\n",
            "\u001b[32m    571\u001b[39m \u001b[38;5;66;03m# If there are any missing file and the flag is active, raise\u001b[39;00m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\transformers\\utils\\hub.py:478\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n",
            "\u001b[32m    475\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n",
            "\u001b[32m    477\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    479\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    492\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[32m    493\u001b[39m         snapshot_download(\n",
            "\u001b[32m    494\u001b[39m             path_or_repo_id,\n",
            "\u001b[32m    495\u001b[39m             allow_patterns=full_filenames,\n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m    504\u001b[39m             local_files_only=local_files_only,\n",
            "\u001b[32m    505\u001b[39m         )\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
            "\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n",
            "\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n",
            "\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n",
            "\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n",
            "\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n",
            "\u001b[32m    992\u001b[39m         local_dir=local_dir,\n",
            "\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n",
            "\u001b[32m   1008\u001b[39m     )\n",
            "\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n",
            "\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n",
            "\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n",
            "\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n",
            "\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:1171\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n",
            "\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n",
            "\u001b[32m   1170\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1180\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m   1183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n",
            "\u001b[32m   1184\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:1738\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n",
            "\u001b[32m   1731\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n",
            "\u001b[32m   1732\u001b[39m             logger.warning(\n",
            "\u001b[32m   1733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m   1734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m   1735\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m   1736\u001b[39m             )\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1738\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m   1739\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1740\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1741\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1742\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1743\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1744\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m   1745\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m   1747\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m   1748\u001b[39m _chmod_and_move(incomplete_path, destination_path)\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:426\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n",
            "\u001b[32m    420\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[32m    421\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
            "\u001b[32m    422\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file is too large to be downloaded using the regular download method. Use `hf_transfer` or `hf_xet` instead.\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m    423\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Try `pip install hf_transfer` or `pip install hf_xet`.\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m    424\u001b[39m         )\n",
            "\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHF_HUB_DOWNLOAD_TIMEOUT\u001b[49m\n",
            "\u001b[32m    428\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    430\u001b[39m hf_raise_for_status(r)\n",
            "\u001b[32m    431\u001b[39m total: Optional[\u001b[38;5;28mint\u001b[39m] = _get_file_length_from_http_response(r)\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n",
            "\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m429\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n",
            "\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:310\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n",
            "\u001b[32m    307\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n",
            "\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n",
            "\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n",
            "\u001b[32m    584\u001b[39m send_kwargs = {\n",
            "\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n",
            "\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n",
            "\u001b[32m    587\u001b[39m }\n",
            "\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n",
            "\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\sessions.py:724\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n",
            "\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n",
            "\u001b[32m    722\u001b[39m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n",
            "\u001b[32m    723\u001b[39m     gen = \u001b[38;5;28mself\u001b[39m.resolve_redirects(r, request, **kwargs)\n",
            "\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     history = \u001b[43m[\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[32m    725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[32m    726\u001b[39m     history = []\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\sessions.py:265\u001b[39m, in \u001b[36mSessionRedirectMixin.resolve_redirects\u001b[39m\u001b[34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[39m\n",
            "\u001b[32m    263\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m req\n",
            "\u001b[32m    264\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
            "\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    276\u001b[39m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m.cookies, prepared_request, resp.raw)\n",
            "\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n",
            "\u001b[32m    700\u001b[39m start = preferred_clock()\n",
            "\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
            "\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:96\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n",
            "\u001b[32m     94\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[32m     98\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\requests\\adapters.py:690\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n",
            "\u001b[32m    688\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n",
            "\u001b[32m    689\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n",
            "\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n",
            "\u001b[32m    691\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n",
            "\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
            "\n",
            "\u001b[31mReadTimeout\u001b[39m: (ReadTimeoutError(\"HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: eba1c894-fced-4a0c-bfb0-f882bfb13e02)')"
          ]
        }
      ],
      "source": [
        "# from sentence_transformers import SentenceTransformer\n",
        "# # Thay thế phần embed_model của bạn\n",
        "# import os\n",
        "\n",
        "# # Tăng thời gian chờ download lên 5 phút\n",
        "# os.environ[\"HF_HUB_DOWNLOAD_TIMEOUT\"] = \"300\"\n",
        "# class HFEmbeddingModel:\n",
        "#     def __init__(self, model_name: str):\n",
        "#         # Chọn model nhẹ hơn\n",
        "#         self._model = SentenceTransformer(model_name)\n",
        "#     def embed(self, texts: list[str]) -> list[list[float]]:\n",
        "#         return self._model.encode(texts).tolist()\n",
        "#     def embed_query(self, text: str) -> list[float]:\n",
        "#         return self._model.encode([text]).tolist()[0]\n",
        "\n",
        "# # Thay đổi model_name thành one-of-the-above\n",
        "# embed_model = HFEmbeddingModel(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "\n",
        "# Nếu bạn đã cài hf_xet hoặc hf_transfer, sẽ fallback nhanh hơn cho file lớn\n",
        "# pip install \"huggingface_hub[hf_xet]\" hf_transfer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "File path path/to/your.pdf is not a valid file or url",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Vector store đã sẵn sàng tại ./chromadb_offline\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# 1) Đọc và tách PDF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     loader = \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath/to/your.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# sửa đường dẫn\u001b[39;00m\n\u001b[32m     10\u001b[39m     docs = loader.load()\n\u001b[32m     11\u001b[39m     splitter = RecursiveCharacterTextSplitter(chunk_size=\u001b[32m1000\u001b[39m, chunk_overlap=\u001b[32m200\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:281\u001b[39m, in \u001b[36mPyPDFLoader.__init__\u001b[39m\u001b[34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    240\u001b[39m     file_path: Union[\u001b[38;5;28mstr\u001b[39m, PurePath],\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m     extraction_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    251\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize with a file path.\u001b[39;00m\n\u001b[32m    253\u001b[39m \n\u001b[32m    254\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m        `aload` methods to retrieve parsed documents with content and metadata.\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m.parser = PyPDFParser(\n\u001b[32m    283\u001b[39m         password=password,\n\u001b[32m    284\u001b[39m         mode=mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    290\u001b[39m         extraction_kwargs=extraction_kwargs,\n\u001b[32m    291\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:140\u001b[39m, in \u001b[36mBasePDFLoader.__init__\u001b[39m\u001b[34m(self, file_path, headers)\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_path = \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(\u001b[38;5;28mself\u001b[39m.file_path):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not a valid file or url\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.file_path)\n",
            "\u001b[31mValueError\u001b[39m: File path path/to/your.pdf is not a valid file or url"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "def main():\n",
        "    # 1) Đọc và tách PDF\n",
        "    loader = PyPDFLoader(\"path/to/your.pdf\")  # sửa đường dẫn\n",
        "    docs = loader.load()\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = splitter.split_documents(docs)\n",
        "\n",
        "    # 2) Tạo embeddings offline với SentenceTransformers\n",
        "    # Mô hình phổ biến: all-MiniLM-L6-v2, rất nhanh và gọn\n",
        "    hf_emb = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    )\n",
        "\n",
        "    # 3) Lưu vector store vào Chroma\n",
        "    vectordb = Chroma.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=hf_emb,\n",
        "        persist_directory=\"./chromadb_offline\"\n",
        "    )\n",
        "    vectordb.persist()\n",
        "\n",
        "    print(\"✅ Vector store đã sẵn sàng tại ./chromadb_offline\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llama_index.storage'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1) Imports (đường dẫn internal có thể khác tùy version)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstorage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstorage_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StorageContext\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mservice_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ServiceContext\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvector_stores\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChromaVectorStore\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'llama_index.storage'"
          ]
        }
      ],
      "source": [
        "# 1) Imports (đường dẫn internal có thể khác tùy version)\n",
        "import chromadb\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from llama_index.service_context import ServiceContext\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# 2) Khởi tạo ChromaVectorStore (giữ nguyên hai hàm offline của bạn)\n",
        "chroma_client     = chromadb.PersistentClient(path=\"./chroma_store\")\n",
        "chroma_collection = chroma_client.get_or_create_collection(\"report_collection\")\n",
        "vector_store = ChromaVectorStore(\n",
        "    chroma_collection=chroma_collection,\n",
        "    embedding_function=embedding_fn,\n",
        "    query_embedding_function=embed_query_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "WXT2TvRJmpAW"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "\n******\nCould not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nConsider using embed_model='local'.\nVisit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules\n******",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\llama_index\\core\\embeddings\\utils.py:59\u001b[39m, in \u001b[36mresolve_embed_model\u001b[39m\u001b[34m(embed_model, callback_manager)\u001b[39m\n\u001b[32m     58\u001b[39m     embed_model = OpenAIEmbedding()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[43mvalidate_openai_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\llama_index\\embeddings\\openai\\utils.py:104\u001b[39m, in \u001b[36mvalidate_openai_api_key\u001b[39m\u001b[34m(api_key)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m openai_api_key:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(MISSING_API_KEY_ERROR_MESSAGE)\n",
            "\u001b[31mValueError\u001b[39m: No API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m vector_store = ChromaVectorStore(\n\u001b[32m     11\u001b[39m     chroma_collection=chroma_collection,\n\u001b[32m     12\u001b[39m     embedding_function=embedding_fn,\n\u001b[32m     13\u001b[39m     query_embedding_function=embed_query_fn,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# --- Khi tạo index, bỏ luôn embed_model=, chỉ pass vector_store ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m index = \u001b[43mVectorStoreIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvector_store\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:71\u001b[39m, in \u001b[36mVectorStoreIndex.__init__\u001b[39m\u001b[34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m._use_async = use_async\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m._store_nodes_override = store_nodes_override\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m._embed_model = resolve_embed_model(\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     embed_model \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mSettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_model\u001b[49m, callback_manager=callback_manager\n\u001b[32m     72\u001b[39m )\n\u001b[32m     74\u001b[39m \u001b[38;5;28mself\u001b[39m._insert_batch_size = insert_batch_size\n\u001b[32m     75\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     76\u001b[39m     nodes=nodes,\n\u001b[32m     77\u001b[39m     index_struct=index_struct,\n\u001b[32m   (...)\u001b[39m\u001b[32m     83\u001b[39m     **kwargs,\n\u001b[32m     84\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\llama_index\\core\\settings.py:64\u001b[39m, in \u001b[36m_Settings.embed_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the embedding model.\"\"\"\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28mself\u001b[39m._embed_model = \u001b[43mresolve_embed_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdefault\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._callback_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m._embed_model.callback_manager = \u001b[38;5;28mself\u001b[39m._callback_manager\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\Project_self\\t\\Lib\\site-packages\\llama_index\\core\\embeddings\\utils.py:66\u001b[39m, in \u001b[36mresolve_embed_model\u001b[39m\u001b[34m(embed_model, callback_manager)\u001b[39m\n\u001b[32m     61\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     62\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`llama-index-embeddings-openai` package not found, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mplease run `pip install llama-index-embeddings-openai`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     64\u001b[39m         )\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     67\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m******\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCould not load OpenAI embedding model. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf you intended to use OpenAI, please check your OPENAI_API_KEY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mConsider using embed_model=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mVisit our documentation for more embedding options: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.llamaindex.ai/en/stable/module_guides/models/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33membeddings.html#modules\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m******\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m         )\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# for image multi-modal embeddings\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embed_model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m embed_model.startswith(\u001b[33m\"\u001b[39m\u001b[33mclip\u001b[39m\u001b[33m\"\u001b[39m):\n",
            "\u001b[31mValueError\u001b[39m: \n******\nCould not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nConsider using embed_model='local'.\nVisit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules\n******"
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# --- Chroma client + collection như trước ---\n",
        "chroma_client     = chromadb.PersistentClient(path=\"./chroma_store\")\n",
        "chroma_collection = chroma_client.get_or_create_collection(\"report_collection\")\n",
        "\n",
        "# --- Trả về chính xác 2 hàm bạn đã định nghĩa ---\n",
        "vector_store = ChromaVectorStore(\n",
        "    chroma_collection=chroma_collection,\n",
        "    embedding_function=embedding_fn,\n",
        "    query_embedding_function=embed_query_fn,\n",
        ")\n",
        "\n",
        "# --- Khi tạo index, bỏ luôn embed_model=, chỉ pass vector_store ---\n",
        "index = VectorStoreIndex(\n",
        "    nodes,\n",
        "    embed_model=False,  \n",
        "    vector_store=vector_store\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG6YwCYRpeSs",
        "outputId": "cba5b33b-311c-45f7-daf6-ebd0547918d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The main objective of this research project, as described in the provided context, is to develop and evaluate a hybrid model for the classification of lung diseases in chest X-ray (CXR) images. The model is designed to improve the accuracy and interpretability of the diagnosis, with a focus on enhancing clinical plausibility and real-world applicability. The project involves the use of Convolutional Neural Networks (CNN), InceptionV3, and Vision Transformer (ViT) architectures, with transfer learning and fine-tuning on a CXR dataset. The research aims to compare the performance of these models and integrate them into a hybrid model that leverages the strengths of each architecture. The project also emphasizes the use of Grad-CAM for visualizing the regions of interest in the images, thereby enhancing the interpretability of the model's predictions.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "llm = OpenRouter(\n",
        "    model=\"mistralai/mistral-7b-instruct:free\",\n",
        "    api_key=\"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\"\n",
        ")\n",
        "\n",
        "query_engine = index.as_query_engine(\n",
        "    llm=llm,\n",
        "    response_mode=\"tree_summarize\"\n",
        ")\n",
        "\n",
        "response = query_engine.query(\"What is the main objective of this research project?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 1) Đọc và tách PDF\n",
        "    loader = PyPDFLoader(r\"pdf_place/Hands-On Machine Learning with Scikit-Learn and TensorFlow_ Concepts, Tools, and Techniques to Build Intelligent Systems ( PDFDrive ).pdf\")  # sửa đường dẫn\n",
        "    docs = loader.load()\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = splitter.split_documents(docs)\n",
        "\n",
        "    # 2) Tạo embeddings offline với SentenceTransformers\n",
        "    # Mô hình phổ biến: all-MiniLM-L6-v2, rất nhanh và gọn\n",
        "    hf_emb = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        encode_kwargs={\"batch_size\": 128} \n",
        "    )\n",
        "\n",
        "    # 3) Lưu vector store vào Chroma và tăng 1 với các file mới\n",
        "    persist_dir = \"./chromadb_v3\"  \n",
        "\n",
        "    vectordb = Chroma.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=hf_emb,\n",
        "        persist_directory=persist_dir\n",
        "    )\n",
        "\n",
        "    print(\"✅ Vector store đã sẵn sàng tại ./chromadb_offline\")\n",
        "\n",
        "if __name__ == \"__main__\":"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "t",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
